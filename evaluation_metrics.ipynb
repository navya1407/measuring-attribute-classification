{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihAbTjTFjbFO",
        "outputId": "66d1568e-5bab-46a3-89e6-fef2bd4c3634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jcrvjUBtNk9",
        "outputId": "288b298f-2e46-435b-cd51-4ed724e97f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# download necessary resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ent(text):\n",
        "  # lowercase the text\n",
        "   text = text.lower()\n",
        "   text=re.sub(r'\\b(a|an|the)\\b', '', text)\n",
        "   text=text.replace(\"'s\",\"\")\n",
        "   text=text.replace(\" 's\",\"\")\n",
        "\n",
        "\n",
        "# tokenize the text\n",
        "   tokens = nltk.word_tokenize(text)\n",
        "   for i in range(len(tokens)):\n",
        "     w=tokens[i]\n",
        "\n",
        "     w=w.replace(\" \",\"\")\n",
        "     tokens[i]=w\n",
        "   #stop_words = set(stopwords.words('english'))\n",
        "   #filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "   #text = ' '.join(filtered_tokens)\n",
        "\n",
        "   return tokens\n",
        "\n",
        "\n",
        "def preprocess_attr(text):\n",
        "  # lowercase the text\n",
        "   text = text.lower()\n",
        "   '''text=text.replace(\"'s\",\"\")\n",
        "   text=text.replace(\" 's\",\"\")'''\n",
        "\n",
        "# tokenize the text\n",
        "   tokens = nltk.word_tokenize(text)\n",
        "   for i in range(len(tokens)):\n",
        "     w=tokens[i]\n",
        "\n",
        "     w=w.replace(\" \",\"\")\n",
        "     tokens[i]=w\n",
        "\n",
        "# remove stopwords\n",
        "   stop_words = set(stopwords.words('english'))\n",
        "   filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "\n",
        "\n",
        "   # remove special characters using regex\n",
        "   preprocessed_text = ' '.join(tokens)\n",
        "   # process the text with spaCy\n",
        "   doc = nlp(preprocessed_text)\n",
        "\n",
        "# lemmatize each token and join them back into a string\n",
        "   lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
        "   text = re.sub('[^a-zA-Z0-9\\s]', '',  lemmatized_text)\n",
        "   #text=re.sub('[^a-zA-Z0-9\\s]', '',  preprocessed_text)\n",
        "   tokens = nltk.word_tokenize(text)\n",
        "   return tokens\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def relaxed_precision(pred, gt):\n",
        "    # split predicted and ground truth into words\n",
        "\n",
        "\n",
        "    # calculate overlap\n",
        "    overlap = len(set(pred).intersection(set(gt)))\n",
        "\n",
        "    # calculate relaxed precision\n",
        "    if(len(pred)!=0):\n",
        "       rp = overlap / len(pred)\n",
        "    else:\n",
        "      rp=0\n",
        "\n",
        "    return rp\n",
        "\n",
        "def relaxed_recall(pred, gt):\n",
        "\n",
        "\n",
        "    # calculate overlap\n",
        "    overlap = len(set(pred).intersection(set(gt)))\n",
        "    if(len(gt)!=0):\n",
        "    # calculate relaxed recall\n",
        "      rr = overlap / len(gt)\n",
        "    else:\n",
        "      rr=0\n",
        "\n",
        "    return rr\n"
      ],
      "metadata": {
        "id": "RM5utrVjLlFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test data 25 samples of each sentence length"
      ],
      "metadata": {
        "id": "nod2NYnml1_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#annotated ground truth\n",
        "import json\n",
        "with open ('/content/drive/MyDrive/MTP Project/test_data_25_each.json') as f:\n",
        "  test=json.load(f)\n",
        "ground_truth={}\n",
        "for i in test:\n",
        "  ground_truth[i['sentence']]=[i['entity'],i['measuring attribute'],i['quantity']]\n",
        "len(ground_truth)"
      ],
      "metadata": {
        "id": "wVWGUqE4mM_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ground truth values filtered out entity and attribute\n",
        "gt=[]\n",
        "for g in ground_truth:\n",
        "  t={}\n",
        "  t['sentence']=g\n",
        "  t['entity']=ground_truth[g][0]\n",
        "  t['attribute']=ground_truth[g][1]\n",
        "  gt.append(t)"
      ],
      "metadata": {
        "id": "GrMSklxdmXJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TprfDrbjvJ6"
      },
      "outputs": [],
      "source": [
        "#rule based predictions\n",
        "import json\n",
        "with open ('/content/drive/MyDrive/MTP Project/rule_test_25samples_predictions.json') as f:\n",
        "  test=json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rule based predictions\n",
        "rule_ent,rule_attr=[],[]\n",
        "for i in test:\n",
        "  rule_ent.append(i['entity'])\n",
        "  rule_attr.append(i['attribute'])\n",
        "len(rule_ent),len(rule_attr)"
      ],
      "metadata": {
        "id": "RUR9EaN8nZvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_82uHdgZAGq",
        "outputId": "81a389a4-8a5a-4c29-c8c7-330fe24ed107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#100 sentences list\n",
        "sent=[]\n",
        "for i in test:\n",
        "  sent.append(i['sentence'])\n",
        "len(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEYvBNi-SUqm"
      },
      "outputs": [],
      "source": [
        "#ground truth values filtered out entity and attribute\n",
        "gt=[]\n",
        "for g in ground_truth:\n",
        "  t={}\n",
        "  t['sentence']=g\n",
        "  t['entity']=ground_truth[g][0]\n",
        "  t['attribute']=ground_truth[g][1]\n",
        "  gt.append(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR3ghhAbSvJe",
        "outputId": "2d016b34-7b02-4623-bb7c-363f950ef702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'At the time Ibn Taymiyyah was 42 years old .',\n",
              " 'entity': 'Ibn Taymiyyah',\n",
              " 'attribute': 'age'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "gt[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esWhwO9jQehM",
        "outputId": "f8433efd-9aea-4d5d-a49a-101db20d5b38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#gpt 300 samples attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/gpt_out_attr_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_300=[]\n",
        "for i in data:\n",
        "  attr_300.append(i['attribute'])\n",
        "len(attr_300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmbBw5Hz5Hn2",
        "outputId": "1c79e1cd-baa0-4b31-e594-9cc9f5ea4277"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#gpt 200 samples attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/gpt_out_attr_200.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_200=[]\n",
        "for i in data:\n",
        "  attr_200.append(i['attribute'])\n",
        "len(attr_200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF8GhaD3hrdq",
        "outputId": "ef43b8db-5ea0-47b2-dd9c-e0f736fe0c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#gpt 300 samples joint entity and attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/gpt_out_ent_attr_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_300,ent_300=[],[]\n",
        "for i in data:\n",
        "  attr_ent_300.append(i['attribute'])\n",
        "  ent_300.append(i['entity'])\n",
        "len(attr_ent_300),len(ent_300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_No1I73ohrjE",
        "outputId": "645f4dad-d925-4678-a7ec-c3b3d66b34eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#gpt 200 samples joint entity and attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/gpt_out_ent_attr_200.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_200,ent_200=[],[]\n",
        "for i in data:\n",
        "  attr_ent_200.append(i['attribute'])\n",
        "  ent_200.append(i['entity'])\n",
        "len(attr_ent_200),len(ent_200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7VZ2ljZC5ta"
      },
      "outputs": [],
      "source": [
        "#t5 joint entity attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100_ent_attr.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in data:\n",
        "  attr_ent_t5.append(i['attribute'])\n",
        "  ent_t5.append(i['entity'])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EIRmE0bDLr7",
        "outputId": "f958b1d4-b68a-4f72-db60-ec62899106b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#t5 attribute extraction\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_t5 = []\n",
        "for i in data:\n",
        "  attr_t5.append(i['attribute'])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#t5 attribute extraction 300 samples training\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100_train_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_t5_300 = []\n",
        "for i in data:\n",
        "  attr_t5_300.append(i['attribute'])\n",
        "\n",
        "len(attr_t5_300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Pc2qe4MwAQ",
        "outputId": "653b74a2-b10e-42ac-8c5e-5eb78b9f897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cce7MAVlTlgg",
        "outputId": "76e04daa-ca67-424c-f981-a39365feb687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#ground truth\n",
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in ground_truth:\n",
        "  ground_truth_attr.append(ground_truth[i][1])\n",
        "  ground_truth_ent.append(ground_truth[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100_ent_attr_train_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_t5_300,ent_t5_300=[],[]\n",
        "for i in data:\n",
        "  attr_ent_t5_300.append(i['attribute'])\n",
        "  ent_t5_300.append(i['entity'])\n",
        "len(attr_ent_t5_300),len(ent_t5_300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "046R2H47UVw2",
        "outputId": "78788acf-7e5c-41f9-9ca0-b69ca14c8f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#f1 -t5-300 samples ent-attr"
      ],
      "metadata": {
        "id": "XOADSJW-YGJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htEsUpLVYRXH",
        "outputId": "c4a35509-e71f-4bdc-d029-5f11b0b415dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7166666666666666\n",
            "Relaxed recall for attribute: 0.5914603174603175\n",
            "f1 score for attribute: 0.6480714782636833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7Xz_95DYRav",
        "outputId": "9e9fd9f2-d9e1-4748-8ec1-26226c48ebba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for entity : 0.765\n",
            "Relaxed recall for entity: 0.7735\n",
            "f1 score for attribute: 0.7692265193370166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#f1 attribute -- 300 samples -- t5"
      ],
      "metadata": {
        "id": "mn0ulaFMM8pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-qeKV3TNFIl",
        "outputId": "c11eb85c-bdec-4aa2-e4bc-9e1c0bd132ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.69625\n",
            "Relaxed recall for attribute: 0.5434682539682539\n",
            "f1 score for attribute: 0.6104447855215439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imdt-gwpljrw"
      },
      "source": [
        "##relaxed precision and relaxed recall of entity and attribute -- 200 samples -- gpt3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4twRXWRVP8a",
        "outputId": "a4cecad4-768b-4d08-e904-493fe84bdc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7932380952380953\n",
            "Relaxed recall for attribute: 0.7076666666666668\n",
            "f1 score for attribute: 0.7480130291781677\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K16LGC-XuZSG",
        "outputId": "1a356281-062b-4e54-8860-db6c7204dbec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7475\n",
            "Relaxed recall for entity: 0.742\n",
            "f1 score for attribute: 0.7447398455857671\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_200[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_200[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VuzyQ1vEAN"
      },
      "source": [
        "##relaxed precision and relaxed recall of entity and attribute -- 300 samples -- gpt3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqAcaXoQvHpC",
        "outputId": "9f5a7fa8-d712-41f1-a53b-c83a3e4228f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7696666666666667\n",
            "Relaxed recall for attribute: 0.6887857142857143\n",
            "f1 score for attribute: 0.7269834952248796\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAO8XRsvHsR",
        "outputId": "cdfe6ffc-17a9-4d46-a718-449e8fbf8d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7425\n",
            "Relaxed recall for entity: 0.737\n",
            "f1 score for attribute: 0.7397397769516729\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF1jMFLAVlgS"
      },
      "source": [
        "##relaxed precision and relaxed recall of  attribute -- 300 samples -- gpt3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwnXttFxvHvv",
        "outputId": "ab82448b-e7f2-4b08-967a-8c3cea3e249b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7582857142857143\n",
            "Relaxed recall for attribute: 0.603920634920635\n",
            "f1 score for attribute: 0.6723568573725766\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8LGmfWx46-G"
      },
      "source": [
        "##relaxed precision and relaxed recall of  attribute -- 200 samples -- gpt3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMF-vLUA45v5",
        "outputId": "f5d08b21-f803-423c-efd9-4ee8ee48a41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7378095238095237\n",
            "Relaxed recall for attribute: 0.6545079365079366\n",
            "f1 score for attribute: 0.6936667860997288\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyyqPgv7V7qc"
      },
      "source": [
        "##relaxed precision and relaxed recall of  attribute -- rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KS3spwWV_53",
        "outputId": "08382f0d-ce85-469a-80a8-66f6cee0f64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6934999999999999\n",
            "Relaxed recall for attribute: 0.6037539682539682\n",
            "f1 score for attribute: 0.645522599630477\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWpUbUvwfCr9",
        "outputId": "a3a7d576-ee8c-4c14-eb31-1cc9c23fbd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.8483333333333333\n",
            "Relaxed recall for entity: 0.8286904761904761\n",
            "f1 score for attribute: 0.8383968670878587\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bilmIJb3x363"
      },
      "source": [
        "##relaxed precision and relaxed recall of  attribute -- t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbyI2yntV_9M",
        "outputId": "396d221b-df94-436b-a9d0-2d5d366a9c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.6915\n",
            "Relaxed recall for attribute: 0.5990873015873016\n",
            "f1 score for attribute: 0.6419850381885938\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfZh48kuFJmT"
      },
      "source": [
        "##relaxed precision and relaxed recall of entity attribute -- t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JImEK4FrWAAm",
        "outputId": "552a5881-c41c-456a-a242-18858afe1995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6856666666666668\n",
            "Relaxed recall for attribute: 0.5913888888888889\n",
            "f1 score for attribute: 0.6350477806296313\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuqH5hK_RfiA",
        "outputId": "2778cc05-8584-4587-817c-d01a9da6ee35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7983333333333335\n",
            "Relaxed recall for entity: 0.778\n",
            "f1 score for attribute: 0.7880355254810744\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2tCenXoMWn6"
      },
      "source": [
        "#Splitting test data to buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urQC0zIBMZ0X",
        "outputId": "7406f460-198d-48dc-d89b-bb1c629f376e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import re\n",
        "sen_0=[]\n",
        "for i in sent:\n",
        "  if(len(re.findall(r'\\w+', i))<11):\n",
        "    sen_0.append(i)\n",
        "len(sen_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_08e9YpMk4v",
        "outputId": "cfd96722-ac31-47ae-d2b2-6115be2da122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import re\n",
        "sen_10=[]\n",
        "for i in sent:\n",
        "  if(len(re.findall(r'\\w+', i))>10 and len(re.findall(r'\\w+', i))<21):\n",
        "    sen_10.append(i)\n",
        "len(sen_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaU_DfclMoGp",
        "outputId": "890e0784-298b-4403-fc91-1a6a9ada74d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import re\n",
        "sen_20=[]\n",
        "for i in sent:\n",
        "  if(len(re.findall(r'\\w+', i))>20 and len(re.findall(r'\\w+', i))<31):\n",
        "    sen_20.append(i)\n",
        "len(sen_20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_os-jbDMwSr",
        "outputId": "449f923b-923b-4a6d-dc84-f3011de56e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import re\n",
        "sen_30=[]\n",
        "for i in sent:\n",
        "  if(len(re.findall(r'\\w+', i))>30):\n",
        "    sen_30.append(i)\n",
        "len(sen_30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lilQqG7pNpO6"
      },
      "outputs": [],
      "source": [
        "#rule based\n",
        "with open ('/content/drive/MyDrive/MTP Project/t5_data/test_data_100_seperate.json') as f:\n",
        "  test=json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpunMLlmNyfX",
        "outputId": "3dd69e2d-e2e9-45e7-db72-a510e567bc10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test_dict={}\n",
        "for i in test:\n",
        "  test_dict[i['sentence']]=[i['entity'],i['attribute']]\n",
        "\n",
        "len(test_dict)\n",
        "#sentence --> (entity,attribute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E_7i9ExOGy5",
        "outputId": "b7c00812-a03d-41bd-9d3e-13eb526f50d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#t5 joint\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100_ent_attr.json\") as f:\n",
        "  data=json.load(f)\n",
        "ent_attr={}\n",
        "for i in data:\n",
        "  ent_attr[i['sentence']]=[i['entity'],i['attribute']]\n",
        "len(ent_attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYoFOZG2PQVK",
        "outputId": "a2341574-a9f8-4ae7-8e6b-76b5827f6292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#t5 attribute\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_test_100.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr={}\n",
        "for i in data:\n",
        "  attr[i['sentence']]=i['attribute']\n",
        "len(attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwKZTuzug98l"
      },
      "outputs": [],
      "source": [
        "#gpt attribute -300\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/out_attr_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_300={}\n",
        "for i in data:\n",
        "  attr_300[i['sentence']]=i['attribute']\n",
        "len(attr_300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCLHbw3JiBVh",
        "outputId": "20cf7783-bad2-4f94-ad04-6bd2752da34a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#gpt attribute -200\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/out_attr_200.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_200={}\n",
        "for i in data:\n",
        "  attr_200[i['sentence']]=i['attribute']\n",
        "len(attr_200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scmd5Z9oibQX",
        "outputId": "f722cebe-ab4a-4a1e-fa29-5f8ae4f96d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#gpt joint entity attribute -300\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/out_ent_attr_300.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_300={}\n",
        "for i in data:\n",
        "  attr_ent_300[i['sentence']]=[i['entity'],i['attribute']]\n",
        "\n",
        "len(attr_ent_300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCb1fXaEPSgw",
        "outputId": "4ff29498-216b-4208-e323-82d844de49c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#gpt joint entity attribute -200\n",
        "with open(\"/content/drive/MyDrive/MTP Project/gpt_data/out_ent_attr_200.json\") as f:\n",
        "  data=json.load(f)\n",
        "attr_ent_200={}\n",
        "for i in data:\n",
        "  attr_ent_200[i['sentence']]=[i['entity'],i['attribute']]\n",
        "\n",
        "len(attr_ent_200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo_xlMvNPLp"
      },
      "source": [
        "#performance of rule based t5 on sen len <11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjjg5tdQMzlq",
        "outputId": "1537520c-6a29-4854-9525-24223d068741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_0:\n",
        "  ground_truth_attr.append(ground_truth[i][1])\n",
        "  ground_truth_ent.append(ground_truth[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkO7VK1_NnvS",
        "outputId": "027431df-e87b-4918-fd00-92360c9eee6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_0:\n",
        "  rule_attr.append(test_dict[i][1])\n",
        "  rule_ent.append(test_dict[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYMwAKtvOzbT"
      },
      "outputs": [],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_0:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lSa-aqZQDWl"
      },
      "outputs": [],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_0:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZmX306OQtEa",
        "outputId": "2240efec-3599-47bb-ecb3-a08f30153a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "gpt_ent_200,ent_200=[],[]\n",
        "for i in sen_30:\n",
        "  gpt_ent_200.append(attr_ent_200[i][1])\n",
        "  ent_200.append(attr_ent_200[i][0])\n",
        "len(gpt_ent_200),len(ent_200)\n",
        "gpt_ent_300,ent_300=[],[]\n",
        "for i in sen_30:\n",
        "  gpt_ent_300.append(attr_ent_300[i][1])\n",
        "  ent_300.append(attr_ent_300[i][0])\n",
        "len(gpt_ent_300),len(ent_300)\n",
        "gpt_attr_300=[]\n",
        "for i in sen_30:\n",
        "  gpt_attr_300.append(attr_300[i])\n",
        "\n",
        "len(gpt_attr_300)\n",
        "gpt_attr_200=[]\n",
        "for i in sen_30:\n",
        "  gpt_attr_200.append(attr_200[i])\n",
        "\n",
        "len(gpt_attr_200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3uFIEx6Qhfr"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIl8zuL7QS4Q",
        "outputId": "f5a9ab5d-6ae5-4d94-b710-2509e0b0eada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.74\n",
            "Relaxed recall for attribute: 0.6573333333333333\n",
            "f1 score for attribute: 0.6962213740458015\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Ibt1V7Ql4i",
        "outputId": "aee729d3-2f80-4a03-b456-929299d2ec17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9466666666666665\n",
            "Relaxed recall for entity: 0.9333333333333335\n",
            "f1 score for attribute: 0.939952718676123\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FuEQDaxQ496"
      },
      "source": [
        "#t5 - joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtwWjunMQ1xr",
        "outputId": "62f018ff-0485-4a15-cf7e-30589773c258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7266666666666666\n",
            "Relaxed recall for attribute: 0.6653333333333333\n",
            "f1 score for attribute: 0.6946487867177522\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFdLs4zyRNUD",
        "outputId": "f6461f62-9fc4-462b-a2b0-bbf82c3563a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9133333333333333\n",
            "Relaxed recall for entity: 0.9\n",
            "f1 score for attribute: 0.9066176470588235\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yULA6Q4dRPXA"
      },
      "source": [
        "#t5 - attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ha_M7F8RYdY",
        "outputId": "eac62978-ca27-4d27-d9ae-105a4454b387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.74\n",
            "Relaxed recall for attribute: 0.6573333333333333\n",
            "f1 score for attribute: 0.6962213740458015\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LPGVKltmubj"
      },
      "source": [
        "#gpt3-attr 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrIBMDn9m2QL",
        "outputId": "f7da98bb-b555-4457-fc91-cd9e936e90cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7152380952380952\n",
            "Relaxed recall for attribute: 0.6369523809523809\n",
            "f1 score for attribute: 0.6738290436614144\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(gpt_attr_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(gpt_attr_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vt9aJzQoGBB"
      },
      "source": [
        "#gpt3-attr 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D23u6zcZoQaf",
        "outputId": "07705448-c52e-4b0d-f9de-e2dc89d6aae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7298095238095237\n",
            "Relaxed recall for attribute: 0.5783809523809523\n",
            "f1 score for attribute: 0.6453309898216711\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(gpt_attr_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(gpt_attr_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcxEhhziodCv"
      },
      "source": [
        "#gpt-ent-attr 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m76xP5Motme",
        "outputId": "08c9b1bb-0c9a-40bd-b5d3-b7af55d58bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7509523809523809\n",
            "Relaxed recall for attribute: 0.6947619047619048\n",
            "f1 score for attribute: 0.7217651671999498\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(gpt_ent_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(gpt_ent_200[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLxfoOZJowKK",
        "outputId": "9fe19c17-084a-414f-b6a4-1784b1c1175f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for entity : 0.6933333333333335\n",
            "Relaxed recall for entity: 0.68\n",
            "f1 score for attribute: 0.6866019417475729\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_200[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_200[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG7WhhK4okS3"
      },
      "source": [
        "#gpt-ent-attr 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USb783qtouvW",
        "outputId": "31219961-9af5-4be4-9fa5-ac205981b39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.68\n",
            "Relaxed recall for attribute: 0.6196190476190476\n",
            "f1 score for attribute: 0.6484068591528653\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(gpt_ent_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(gpt_ent_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsCxI5k4ovaQ",
        "outputId": "2def2a50-f92a-48bc-93cc-eb8ad75f03f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for entity : 0.68\n",
            "Relaxed recall for entity: 0.64\n",
            "f1 score for attribute: 0.6593939393939394\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfaNUTlwRy-J"
      },
      "source": [
        "##performance of rule based t5 on sen len <21 and len >=11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktNOlewBR-Lx",
        "outputId": "8f6e2743-3a15-4272-f02d-7cd74f576eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_10:\n",
        "  ground_truth_attr.append(ground_truth[i][1])\n",
        "  ground_truth_ent.append(ground_truth[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnduYmACSIr0",
        "outputId": "57b5ff46-21a1-4823-cf88-7fb52e30418e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_10:\n",
        "  rule_attr.append(test_dict[i][1])\n",
        "  rule_ent.append(test_dict[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmMdhluLSNyb",
        "outputId": "2151f20c-3ff1-4e28-9834-9483d030c82a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_10:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzXZIuVUSSWz",
        "outputId": "eaaef420-06cd-4067-ec45-ceb0b0e8e671"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_10:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJe9fJwiTJXR"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlXXlEPqTL8C",
        "outputId": "b35f6d05-1ac7-4f01-f936-caa99bad8ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8733333333333333\n",
            "Relaxed recall for attribute: 0.7294285714285713\n",
            "f1 score for attribute: 0.7949206726484044\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nLST8a5TRDO",
        "outputId": "87397365-3c9d-47df-de6a-e54d5acc83e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9466666666666665\n",
            "Relaxed recall for entity: 0.9520000000000001\n",
            "f1 score for attribute: 0.9493258426966291\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz038FrpTZgA"
      },
      "source": [
        "#t5- joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "947q26grTdYn",
        "outputId": "1644ee16-a9ad-42ef-b826-bf0d4574fc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8733333333333333\n",
            "Relaxed recall for attribute: 0.7294285714285713\n",
            "f1 score for attribute: 0.7949206726484044\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN-G3a1gThNt",
        "outputId": "54afd1ca-461f-4918-d1e5-ea7df664c27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9466666666666665\n",
            "Relaxed recall for entity: 0.9440000000000001\n",
            "f1 score for attribute: 0.9453314527503526\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGLzcM_ETn6r"
      },
      "source": [
        "#t5-attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV1cOe-sTj8I",
        "outputId": "0bdbca8e-ed95-4abd-e75f-ed7edb9fe96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8733333333333333\n",
            "Relaxed recall for attribute: 0.7294285714285713\n",
            "f1 score for attribute: 0.7949206726484044\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri0Zaqz4SYrs"
      },
      "source": [
        "##performance of rule based t5 on sen len <31 and len >=21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqD6VzlNSYJ3",
        "outputId": "6cf78013-5061-450f-e0c4-0b001c234ac9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_20:\n",
        "  ground_truth_attr.append(ground_truth[i][1])\n",
        "  ground_truth_ent.append(ground_truth[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c1Qmn0XSm6H",
        "outputId": "c84f787b-a49f-44f7-d461-9a9842d3e408"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_20:\n",
        "  rule_attr.append(test_dict[i][1])\n",
        "  rule_ent.append(test_dict[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePLtY49LSm86",
        "outputId": "79d90260-3c8e-465c-d92b-081d7ba05402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_20:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOrJuFvqSm_g",
        "outputId": "30e72d85-9fd1-4467-c858-8abaa70e65b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_20:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoHI92qNTNyr"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfhJ-jquTPlq",
        "outputId": "63a88318-6218-44b3-9b42-6ea2abd1719f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.588\n",
            "Relaxed recall for attribute: 0.5028253968253967\n",
            "f1 score for attribute: 0.5420873664910799\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0JUqA9T4Et",
        "outputId": "b55e8852-697d-4864-c2d7-27575c5c369d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7533333333333334\n",
            "Relaxed recall for entity: 0.7034285714285714\n",
            "f1 score for attribute: 0.7275261506276152\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49mZGoZRT896"
      },
      "source": [
        "#t5 - joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HIDn6ioUAI4",
        "outputId": "c1bc69ee-eb3b-4d9d-bf24-7bb5bcd234de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6066666666666667\n",
            "Relaxed recall for attribute: 0.4863174603174603\n",
            "f1 score for attribute: 0.539866198069457\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBia03isUDcF",
        "outputId": "d2ed8e5a-d73c-4cb4-df0a-b06932095c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.66\n",
            "Relaxed recall for entity: 0.622\n",
            "f1 score for attribute: 0.6404368174726989\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmL8gE6TUK1L"
      },
      "source": [
        "#t5 -attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCjPceTUUGVN",
        "outputId": "8a497778-c0c1-4468-8bf8-eca1de0327b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6066666666666667\n",
            "Relaxed recall for attribute: 0.5028253968253967\n",
            "f1 score for attribute: 0.5498865966598948\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUMjhCf5S8_V"
      },
      "source": [
        "##performance of rule based t5 on sen  len >=31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQGy_rO4S0vT",
        "outputId": "a9648e24-1fd0-43f3-cadf-73fdee031234"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_30:\n",
        "  ground_truth_attr.append(ground_truth[i][1])\n",
        "  ground_truth_ent.append(ground_truth[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrFAtmWxS0yr",
        "outputId": "50637089-470e-4893-a9d2-d3e9592ea64a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_30:\n",
        "  rule_attr.append(test_dict[i][1])\n",
        "  rule_ent.append(test_dict[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPBVtQh-S01e",
        "outputId": "9a61e90e-31f8-4ae3-8c97-f0e1ea3f9b7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25, 25)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_30:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-GD2hhVSnCj",
        "outputId": "40d07fb9-2a59-47e6-e04c-12eadafca088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_30:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUEZxVz6Uh7z"
      },
      "source": [
        "#rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov33YaUhUpgS",
        "outputId": "3dcbee31-203d-40fa-e6a0-52510a3b51b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.5726666666666667\n",
            "Relaxed recall for attribute: 0.5254285714285715\n",
            "f1 score for attribute: 0.5480315698178665\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7xhwwMMUjLy",
        "outputId": "a2a17f63-9730-4390-ba04-7003098608fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7466666666666666\n",
            "Relaxed recall for entity: 0.726\n",
            "f1 score for attribute: 0.7361883205070167\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teRUNN_QUtiu"
      },
      "source": [
        "#t5- joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J54SHJz-Uvtx",
        "outputId": "e811aa5c-23a5-4af1-a0e6-57f4f570bde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.5359999999999999\n",
            "Relaxed recall for attribute: 0.4844761904761905\n",
            "f1 score for attribute: 0.5089373775081661\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_eQ99ucUyZX",
        "outputId": "0860537f-2254-4e6b-8cd6-cf7e06b3efa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.6733333333333333\n",
            "Relaxed recall for entity: 0.6459999999999999\n",
            "f1 score for attribute: 0.6593835270338554\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfLrLE7jU1vk"
      },
      "source": [
        "#t5-attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BENw14hbU3Oz",
        "outputId": "081eb635-c1fc-4e05-cf85-f5077866c715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.586\n",
            "Relaxed recall for attribute: 0.5187619047619048\n",
            "f1 score for attribute: 0.5503348275862068\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCJZ5batVkZb"
      },
      "source": [
        "#for new test data - performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#following the same above procedure read the prediction files and ground truth, calculate f1"
      ],
      "metadata": {
        "id": "GPK2fvc2pQIn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrJX4pHFVnRE",
        "outputId": "b2eb0860-3edf-4692-bc8f-ccea23b5afcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import json\n",
        "with open (\"/content/drive/MyDrive/MTP Project/t5_data/new_test_data_100_groundtruth.json\") as f:\n",
        "  new_test=json.load(f)\n",
        "len(new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk6nVY7VWaiy",
        "outputId": "6b7acb5c-bfc8-4d32-8902-151b9fe0e32e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in new_test:\n",
        "  ground_truth_attr.append(new_test[i][1])\n",
        "  ground_truth_ent.append(new_test[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIsCoPK1WKkm",
        "outputId": "0197465a-c3cb-4b56-c4b3-64ebb9093545"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#t5 joint\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_new_test_100_ent_attr.json\") as f:\n",
        "    data=json.load(f)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvpZk9vRUaUJ",
        "outputId": "7265d2ab-e3d2-4de5-b438-a9d8055bf699"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ent_attr={}\n",
        "for i in data:\n",
        "  ent_attr[i['sentence']]=[i['entity'],i['attribute']]\n",
        "len(ent_attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_a4-cCcVy3N",
        "outputId": "dcc2170d-45ee-4fa7-a04b-05232ffd0c92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in ent_attr:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#t5 joint -300 samples\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_new_test_100_ent_attr_train_300.json\") as f:\n",
        "    data=json.load(f)\n",
        "ent_attr={}\n",
        "for i in data:\n",
        "  ent_attr[i['sentence']]=[i['entity'],i['attribute']]\n",
        "\n",
        "len(data),len(ent_attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWjPdzGiY9KE",
        "outputId": "bd658afc-c88c-4b2a-a2b2-42b7abdeb1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attr_ent_t5_300,ent_t5_300=[],[]\n",
        "for i in ent_attr:\n",
        "  attr_ent_t5_300.append(ent_attr[i][1])\n",
        "  ent_t5_300.append(ent_attr[i][0])\n",
        "len(attr_ent_t5_300),len(ent_t5_300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QgWvA1yZQ-Z",
        "outputId": "5846ef22-2cf6-40c3-958e-7402c3d2dc33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3BA9bCzXC8X",
        "outputId": "df3c9e61-271f-48c6-ebe0-8cfeeee727b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#read file for t5 predictions\n",
        "attr={}\n",
        "for i in data:\n",
        "  attr[i['sentence']]=i['attribute']\n",
        "len(attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNoDMXwhcNEM",
        "outputId": "2ed97c30-2b0c-4be2-e288-3ef6dc1f22f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in attr:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu3KZnUocS3f"
      },
      "outputs": [],
      "source": [
        "attr_t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIR5YKZPXNRf",
        "outputId": "b13b0e18-c013-4753-fb76-10170de6bbb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#rule based\n",
        "with open(\"/content/drive/MyDrive/MTP Project/t5_data/rule_test_distribution_predictions.json\") as f:\n",
        "    data=json.load(f)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rule_ent_attr={}\n",
        "for i in data:\n",
        "  rule_ent_attr[i['sentence']]=[i['entity'],i['attribute']]\n",
        "len(rule_ent_attr)"
      ],
      "metadata": {
        "id": "W2LZLL6GtDe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsoH1Z2eYW14",
        "outputId": "a9b7653f-3624-4e0e-b8b6-3eb340d63847"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in rule_ent_attr:\n",
        "  rule_attr.append(rule_ent_attr[i][1])\n",
        "  rule_ent.append(rule_ent_attr[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm_NedOrZSlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5405c756-8e75-4352-e23f-a71016a5f48b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#attr t5-300\n",
        "with open(\"/content/drive/MyDrive/MTP Project/test_results/output_new_test_100_train_300.json\") as f:\n",
        "    data=json.load(f)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attr={}\n",
        "for i in data:\n",
        "  attr[i['sentence']]=i['attribute']\n",
        "len(attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wLWae4ZOeEL",
        "outputId": "13a8a1e3-6fcf-4ead-d0d3-45c40e711b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attr_t5_300=[]\n",
        "for i in attr:\n",
        "  attr_t5_300.append(attr[i])\n",
        "\n",
        "len(attr_t5_300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7XSNmX9OjhQ",
        "outputId": "a7189a3b-979b-4460-b41b-d14050434cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#f1 - 300 samples -t5 ent-attr"
      ],
      "metadata": {
        "id": "EL3W8HNNZf9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgHCpF-SZkEU",
        "outputId": "f479bbb3-c8d1-4ef2-f395-a756186f6d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7136666666666668\n",
            "Relaxed recall for attribute: 0.6013492063492063\n",
            "f1 score for attribute: 0.6527113358922981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5_300[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIe--klLaHUY",
        "outputId": "8d5c5c07-b957-489c-ca9b-f5e1589e85ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for entity : 0.7741666666666666\n",
            "Relaxed recall for entity: 0.7821666666666667\n",
            "f1 score for attribute: 0.7781461055186691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#f1 -300 samples -t5"
      ],
      "metadata": {
        "id": "fWfVRI7gOtCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5_300[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89N6VFucOxD_",
        "outputId": "d6a59a2b-28e4-4c13-ee77-84f956f2b408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.767\n",
            "Relaxed recall for attribute: 0.5947619047619047\n",
            "f1 score for attribute: 0.6699884603280064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_rLjuR0acEh"
      },
      "source": [
        "#rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXFQiyB4ad4o",
        "outputId": "9f6b4fb9-32f7-43d3-f858-61e7abe87c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7251666666666666\n",
            "Relaxed recall for attribute: 0.6497539682539683\n",
            "f1 score for attribute: 0.6853921707842684\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2nQXFsAaj4N",
        "outputId": "e161d993-371b-47b4-a810-537e41fd4848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.8683333333333334\n",
            "Relaxed recall for entity: 0.8546904761904761\n",
            "f1 score for attribute: 0.8614578928701387\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubO0SN4IbJnX"
      },
      "source": [
        "#t5 - joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SannHjGEa4kz",
        "outputId": "9266292e-e321-4a32-a50e-2d29418b884d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.7211666666666667\n",
            "Relaxed recall for attribute: 0.6375714285714286\n",
            "f1 score for attribute: 0.676797483659558\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naGHbTvAbP8V",
        "outputId": "f967bb7e-6f4d-476d-c650-7fd176b21ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.8316666666666667\n",
            "Relaxed recall for entity: 0.8173333333333334\n",
            "f1 score for attribute: 0.8244377063540194\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hKeDW-FbyaA"
      },
      "source": [
        "#t5- attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzB7wwjGbcm4",
        "outputId": "d7b18bc0-bc0d-4e12-f363-980049635908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relaxed precision for attribute : 0.7215\n",
            "Relaxed recall for attribute: 0.6380873015873016\n",
            "f1 score for attribute: 0.6772349043827492\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjWb__cieiyl"
      },
      "source": [
        "#splitting data into buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zja6FxmMeqk6",
        "outputId": "15fda8e5-cb10-4f7f-dda1-7ae57f354d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ground truth\n",
        "import json\n",
        "with open (\"/content/drive/MyDrive/MTP Project/t5_data/new_test_data_100_groundtruth.json\") as f:\n",
        "  new_test=json.load(f)\n",
        "len(new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juet-0Aagp6q",
        "outputId": "a7a0519b-bf11-46fd-fbc8-6566a0035b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#rule based\n",
        "with open(\"/content/drive/MyDrive/MTP Project/t5_data/new_test_data_100.json\") as f:\n",
        "    rule=json.load(f)\n",
        "len(rule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2BN7iRUe5Wq",
        "outputId": "95ae8e6e-0453-4509-8a3c-4ba4ddd467f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "sen_0=[]\n",
        "for i in new_test:\n",
        "  if(len(re.findall(r'\\w+', i))<11):\n",
        "    sen_0.append(i)\n",
        "len(sen_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqYrYLFte9rR",
        "outputId": "dca39d88-9339-4aef-87ec-fbd4668d6437"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "sen_10=[]\n",
        "for i in new_test:\n",
        "  if(len(re.findall(r'\\w+', i))>10 and len(re.findall(r'\\w+', i))<21):\n",
        "    sen_10.append(i)\n",
        "len(sen_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceWsMB81fD3c",
        "outputId": "4c51e834-c7e8-4b64-d3de-d156bf00c403"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "sen_20=[]\n",
        "for i in new_test:\n",
        "  if(len(re.findall(r'\\w+', i))>20 and len(re.findall(r'\\w+', i))<31):\n",
        "    sen_20.append(i)\n",
        "len(sen_20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apc1-GEcemMz",
        "outputId": "24c31fd1-d7c4-4e22-b94a-a714cd131551"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sen_30=[]\n",
        "for i in new_test:\n",
        "  if(len(re.findall(r'\\w+', i))>30):\n",
        "    sen_30.append(i)\n",
        "len(sen_30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hflicN_TdZIZ"
      },
      "source": [
        "#performance for sen < 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqTd0U5ciWFO",
        "outputId": "e85a6538-7101-409d-f9f9-2986f983a42f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 7)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_0:\n",
        "  ground_truth_attr.append(new_test[i][1])\n",
        "  ground_truth_ent.append(new_test[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeCM9YCZiZAr",
        "outputId": "e74afe43-0a43-4f3c-fe4a-bc3f6c85072c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 7)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_0:\n",
        "  rule_attr.append(rule[i][1])\n",
        "  rule_ent.append(rule[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2BVShKDidCX",
        "outputId": "416095cf-7bc5-410f-dc48-c3558ce551d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7, 7)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_0:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ySPkJWfd1uD",
        "outputId": "25bda84d-fe05-4ffd-cebd-41710847cf48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_0:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmf7LAYvjxJU"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOR6_eHUkWqk",
        "outputId": "37b678c5-8c7e-436d-d805-172637b3a0ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 1.0\n",
            "Relaxed recall for attribute: 0.9285714285714286\n",
            "f1 score for attribute: 0.962962962962963\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9GobgKHmVRP",
        "outputId": "4b1a1987-b64c-4cfc-9c0b-bdb958df9546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9523809523809523\n",
            "Relaxed recall for entity: 1.0\n",
            "f1 score for attribute: 0.975609756097561\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcSZGyHrmXQb"
      },
      "source": [
        "#T5 - Joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKec12NmjWw",
        "outputId": "7ab52074-d556-4e6f-e2bd-f88b13969f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.9523809523809523\n",
            "Relaxed recall for attribute: 0.9285714285714286\n",
            "f1 score for attribute: 0.9403254972875226\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NQbgBPwm3_u",
        "outputId": "c8647086-ee7f-494b-b264-e7efaf65f587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.8809523809523808\n",
            "Relaxed recall for entity: 0.9285714285714286\n",
            "f1 score for attribute: 0.9041353383458646\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwzg8w4naLM"
      },
      "source": [
        "#t5 - attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMTQpF_Oncyh",
        "outputId": "c62b8029-b6ac-4654-af82-5594f56658cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.9523809523809523\n",
            "Relaxed recall for attribute: 0.9285714285714286\n",
            "f1 score for attribute: 0.9403254972875226\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrgxTSV4di1S"
      },
      "source": [
        "#performance for sen < 21 and sen > 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR4NO3pPirpZ",
        "outputId": "00bb5977-5f45-42ae-a1b7-f89bbb82cc5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 35)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_10:\n",
        "  ground_truth_attr.append(new_test[i][1])\n",
        "  ground_truth_ent.append(new_test[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrAJN8yJivcv",
        "outputId": "03282d0f-b565-435f-d24c-6b56c7827d70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 35)"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_10:\n",
        "  rule_attr.append(rule[i][1])\n",
        "  rule_ent.append(rule[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqqsc7QXizZP",
        "outputId": "69ca702a-ce43-4a7e-fc4d-fce17c8956dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 35)"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_10:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAc7SumaiJYJ",
        "outputId": "71a93da3-f8b7-48e1-9818-7b07987ffb4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_10:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C781ZKaj61V"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jjX46xEkYmX",
        "outputId": "25d4dde6-134e-4f37-bb77-f8725350c3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8666666666666666\n",
            "Relaxed recall for attribute: 0.7419727891156462\n",
            "f1 score for attribute: 0.7994868975627634\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi3-F4QWmUF8",
        "outputId": "dff9cb21-f712-4e77-a810-8cb74a110dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9619047619047618\n",
            "Relaxed recall for entity: 0.9561904761904763\n",
            "f1 score for attribute: 0.9590391072019672\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-wAtGY9mlb4"
      },
      "source": [
        "#T5 - joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwrjnnumozk",
        "outputId": "2b4a65e7-7683-48dd-d5a9-4b8f06387b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8809523809523809\n",
            "Relaxed recall for attribute: 0.7419727891156462\n",
            "f1 score for attribute: 0.8055118094519528\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAXOfoV0m5ox",
        "outputId": "44da47fa-ed3d-4579-ae22-629d29c8f3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.9619047619047618\n",
            "Relaxed recall for entity: 0.9504761904761905\n",
            "f1 score for attribute: 0.9561563270726617\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bVS4OmlngH4"
      },
      "source": [
        "#t5 attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGTendWYnfGB",
        "outputId": "85f8cff9-63fe-43de-905d-a06f6063aacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.8809523809523809\n",
            "Relaxed recall for attribute: 0.7419727891156462\n",
            "f1 score for attribute: 0.8055118094519528\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1uh444Jdsmb"
      },
      "source": [
        "#performance for sen < 31 and sen > 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY_QHe0di6kj",
        "outputId": "fbcde9b7-020d-4221-d67e-160e53c74af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_20:\n",
        "  ground_truth_attr.append(new_test[i][1])\n",
        "  ground_truth_ent.append(new_test[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWmxEQVUi9je",
        "outputId": "6007e260-9e65-4d58-a320-89ed810acdd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_20:\n",
        "  rule_attr.append(rule[i][1])\n",
        "  rule_ent.append(rule[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q789zocTjBP8",
        "outputId": "a17b421d-6d06-4a5d-fae0-7ab430963ed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_20:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEW62MKriNNb",
        "outputId": "eb5f5d69-b710-4139-ee1a-a78f7434d705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "attr_t5=[]\n",
        "for i in sen_20:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGW7j9dOkQCR"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nERldOZmkcfU",
        "outputId": "5f7a3fa9-3bf0-4404-8c24-b4032b71e94e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6000000000000001\n",
            "Relaxed recall for attribute: 0.5362055933484505\n",
            "f1 score for attribute: 0.5663118680149015\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XlsJRe-mSdP",
        "outputId": "a7be2dad-4387-4627-ca32-80932387b7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.8293650793650793\n",
            "Relaxed recall for entity: 0.7917233560090703\n",
            "f1 score for attribute: 0.8101071966997271\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT5hsoxWmqtJ"
      },
      "source": [
        "#T5 -joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm6IbqAfmy7M",
        "outputId": "fb869ecd-d2c0-409c-fd39-23f25a369283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6063492063492064\n",
            "Relaxed recall for attribute: 0.5230725623582766\n",
            "f1 score for attribute: 0.5616407295070147\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hVE8BaUm8cX",
        "outputId": "28a81e5a-f80b-4780-b0d5-ae60013c8794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7738095238095238\n",
            "Relaxed recall for entity: 0.7432539682539683\n",
            "f1 score for attribute: 0.7582240324850842\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTNM9HlNnnWx"
      },
      "source": [
        "#t5 -attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9xl6aounqN-",
        "outputId": "b6b4d23a-41ee-4d5e-b253-56713b1310e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6063492063492064\n",
            "Relaxed recall for attribute: 0.5230725623582766\n",
            "f1 score for attribute: 0.5616407295070147\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR0PFC97dvyS"
      },
      "source": [
        "#performance for sen > 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJEZZJTJjkUS",
        "outputId": "bf3c8dc6-adb5-48e9-b5b0-2f57c6a74612"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 16)"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_attr,ground_truth_ent=[],[]\n",
        "for i in sen_30:\n",
        "  ground_truth_attr.append(new_test[i][1])\n",
        "  ground_truth_ent.append(new_test[i][0])\n",
        "len(ground_truth_attr),len(ground_truth_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp-MatyIjoLL",
        "outputId": "2c8feead-38c1-4675-83ef-03ca3d1b5824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 16)"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rule_attr,rule_ent=[],[]\n",
        "for i in sen_30:\n",
        "  rule_attr.append(rule[i][1])\n",
        "  rule_ent.append(rule[i][0])\n",
        "len(rule_attr),len(rule_ent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3zLoTg0jrmX",
        "outputId": "3dc8c724-894b-4f44-e793-6269bcb609b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 16)"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_ent_t5,ent_t5=[],[]\n",
        "for i in sen_30:\n",
        "  attr_ent_t5.append(ent_attr[i][1])\n",
        "  ent_t5.append(ent_attr[i][0])\n",
        "len(attr_ent_t5),len(ent_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeb6DUl6dguM",
        "outputId": "2fc7032b-0e1b-4e7e-f1f0-1d908b4030a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attr_t5=[]\n",
        "for i in sen_30:\n",
        "  attr_t5.append(attr[i])\n",
        "\n",
        "len(attr_t5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-JFRn2kNBA"
      },
      "source": [
        "#Rule based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRP_Vb2QjtUw",
        "outputId": "cd3d507d-5139-4ef6-a824-decddc84edbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.6239583333333333\n",
            "Relaxed recall for attribute: 0.6241071428571429\n",
            "f1 score for attribute: 0.6240327292237987\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(rule_attr[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM8bHJOSmPs3",
        "outputId": "b34c637f-82a9-4477-8941-56e36a9b7f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.7291666666666666\n",
            "Relaxed recall for entity: 0.734375\n",
            "f1 score for attribute: 0.7317615658362989\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(rule_ent[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Xh8c4SmuLQ"
      },
      "source": [
        "#t5 - joint extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1cQoTScmwUB",
        "outputId": "90ff70a5-3b9c-48d8-8b29-01722391ec3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.5718749999999999\n",
            "Relaxed recall for attribute: 0.5824404761904762\n",
            "f1 score for attribute: 0.5771093850715482\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_ent_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XCyjmmmm-Zr",
        "outputId": "4170d935-3243-46e2-cb38-a49e6bc783d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for entity : 0.6770833333333333\n",
            "Relaxed recall for entity: 0.671875\n",
            "f1 score for attribute: 0.6744691119691119\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_ent)):\n",
        "    rp = relaxed_precision(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    rr = relaxed_recall(preprocess_ent(ent_t5[i]),preprocess_ent(ground_truth_ent[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for entity : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for entity: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umu8US4Hnts8"
      },
      "source": [
        "#t5 - attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BahCaiKHnwZi",
        "outputId": "b9269824-ef2d-469b-f3d9-b29cb8d62b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relaxed precision for attribute : 0.5718749999999999\n",
            "Relaxed recall for attribute: 0.5824404761904762\n",
            "f1 score for attribute: 0.5771093850715482\n"
          ]
        }
      ],
      "source": [
        "\n",
        "relaxed_precisions = []\n",
        "relaxed_recalls = []\n",
        "\n",
        "for i in range(len(ground_truth_attr)):\n",
        "    rp = relaxed_precision(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    rr = relaxed_recall(preprocess_attr(attr_t5[i]),preprocess_attr(ground_truth_attr[i]))\n",
        "    relaxed_precisions.append(rp)\n",
        "    relaxed_recalls.append(rr)\n",
        "\n",
        "# calculate average relaxed precision and recall\n",
        "avg_relaxed_precision = np.mean(relaxed_precisions)\n",
        "avg_relaxed_recall = np.mean(relaxed_recalls)\n",
        "print(f\"Relaxed precision for attribute : {avg_relaxed_precision}\")\n",
        "print(f\"Relaxed recall for attribute: {avg_relaxed_recall}\")\n",
        "print(f\"f1 score for attribute: {(2*avg_relaxed_recall*avg_relaxed_precision)/(avg_relaxed_precision+avg_relaxed_recall)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWgA2kBwC2hK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}